{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "import seaborn\n",
    "import time\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras import backend\n",
    "from keras.models import Model\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "from scipy.misc import imsave\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import PIL.Image as Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=1224x918 at 0x7FC7302D3B48>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the version\n",
    "tf.__version__\n",
    "\n",
    "height = 918\n",
    "width = 1224\n",
    "\n",
    "content_image_path = 'images/Input/group_raw.jpg'\n",
    "content_image = Image.open(content_image_path)\n",
    "content_image = content_image.resize((width, height))\n",
    "content_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=1224x918 at 0x7FC7222746C8>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "style_image_path = 'images/Styles/picasso.jpg'\n",
    "style_image = Image.open(style_image_path)\n",
    "style_image = style_image.resize((width, height))\n",
    "style_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 918, 1224, 3)\n",
      "(1, 918, 1224, 3)\n"
     ]
    }
   ],
   "source": [
    "content_array = np.asarray(content_image, dtype='float32')\n",
    "content_array = np.expand_dims(content_array, axis=0)\n",
    "print(content_array.shape)\n",
    "\n",
    "style_array = np.asarray(style_image, dtype='float32')\n",
    "style_array = np.expand_dims(style_array, axis=0)\n",
    "print(style_array.shape)\n",
    "\n",
    "content_array[:, :, :, 0] -= 103.939\n",
    "content_array[:, :, :, 1] -= 116.779\n",
    "content_array[:, :, :, 2] -= 123.68\n",
    "content_array = content_array[:, :, :, ::-1]\n",
    "\n",
    "style_array[:, :, :, 0] -= 103.939\n",
    "style_array[:, :, :, 1] -= 116.779\n",
    "style_array[:, :, :, 2] -= 123.68\n",
    "style_array = style_array[:, :, :, ::-1]\n",
    "\n",
    "content_image = backend.variable(content_array)\n",
    "style_image = backend.variable(style_array)\n",
    "combination_image = backend.placeholder((1, height, width, 3))\n",
    "\n",
    "input_tensor = backend.concatenate([content_image,\n",
    "                                    style_image,\n",
    "                                    combination_image], axis=0)\n",
    "\n",
    "model = VGG16(input_tensor=input_tensor, weights='imagenet',\n",
    "              include_top=False)\n",
    "\n",
    "layers = dict([(layer.name, layer.output) for layer in model.layers])\n",
    "layers\n",
    "\n",
    "content_weight = 0.025\n",
    "style_weight = 5.0\n",
    "total_variation_weight = 1.0\n",
    "\n",
    "\n",
    "loss = backend.variable(0.)\n",
    "\n",
    "def content_loss(content, combination):\n",
    "    return backend.sum(backend.square(combination - content))\n",
    "\n",
    "layer_features = layers['block2_conv2']\n",
    "content_image_features = layer_features[0, :, :, :]\n",
    "combination_features = layer_features[2, :, :, :]\n",
    "\n",
    "loss += content_weight * content_loss(content_image_features,\n",
    "                                      combination_features)\n",
    "\n",
    "def gram_matrix(x):\n",
    "    features = backend.batch_flatten(backend.permute_dimensions(x, (2, 0, 1)))\n",
    "    gram = backend.dot(features, backend.transpose(features))\n",
    "    return gram\n",
    "  \n",
    "def style_loss(style, combination):\n",
    "    S = gram_matrix(style)\n",
    "    C = gram_matrix(combination)\n",
    "    channels = 3\n",
    "    size = height * width\n",
    "    return backend.sum(backend.square(S - C)) / (4. * (channels ** 2) * (size ** 2))\n",
    "\n",
    "feature_layers = ['block1_conv2', 'block2_conv2',\n",
    "                  'block3_conv3', 'block4_conv3',\n",
    "                  'block5_conv3']\n",
    "for layer_name in feature_layers:\n",
    "    layer_features = layers[layer_name]\n",
    "    style_features = layer_features[1, :, :, :]\n",
    "    combination_features = layer_features[2, :, :, :]\n",
    "    sl = style_loss(style_features, combination_features)\n",
    "    loss += (style_weight / len(feature_layers)) * sl\n",
    "    \n",
    "def total_variation_loss(x):\n",
    "    a = backend.square(x[:, :height-1, :width-1, :] - x[:, 1:, :width-1, :])\n",
    "    b = backend.square(x[:, :height-1, :width-1, :] - x[:, :height-1, 1:, :])\n",
    "    return backend.sum(backend.pow(a + b, 1.25))\n",
    "\n",
    "loss += total_variation_weight * total_variation_loss(combination_image)\n",
    "\n",
    "grads = backend.gradients(loss, combination_image)\n",
    "\n",
    "outputs = [loss]\n",
    "outputs += grads\n",
    "f_outputs = backend.function([combination_image], outputs)\n",
    "\n",
    "def eval_loss_and_grads(x):\n",
    "    x = x.reshape((1, height, width, 3))\n",
    "    outs = f_outputs([x])\n",
    "    loss_value = outs[0]\n",
    "    grad_values = outs[1].flatten().astype('float64')\n",
    "    return loss_value, grad_values\n",
    "\n",
    "class Evaluator(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.loss_value = None\n",
    "        self.grads_values = None\n",
    "\n",
    "    def loss(self, x):\n",
    "        assert self.loss_value is None\n",
    "        loss_value, grad_values = eval_loss_and_grads(x)\n",
    "        self.loss_value = loss_value\n",
    "        self.grad_values = grad_values\n",
    "        return self.loss_value\n",
    "\n",
    "    def grads(self, x):\n",
    "        assert self.loss_value is not None\n",
    "        grad_values = np.copy(self.grad_values)\n",
    "        self.loss_value = None\n",
    "        self.grad_values = None\n",
    "        return grad_values\n",
    "\n",
    "evaluator = Evaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Start of iteration', 0)\n",
      "('Current loss value:', 1.5505115e+11)\n",
      "Iteration 0 completed in 103s\n",
      "('Start of iteration', 1)\n",
      "('Current loss value:', 9.8057634e+10)\n",
      "Iteration 1 completed in 87s\n",
      "('Start of iteration', 2)\n",
      "('Current loss value:', 8.3552469e+10)\n",
      "Iteration 2 completed in 88s\n",
      "('Start of iteration', 3)\n",
      "('Current loss value:', 7.7225812e+10)\n",
      "Iteration 3 completed in 88s\n",
      "('Start of iteration', 4)\n",
      "('Current loss value:', 7.4205299e+10)\n",
      "Iteration 4 completed in 88s\n",
      "('Start of iteration', 5)\n",
      "('Current loss value:', 7.2408556e+10)\n",
      "Iteration 5 completed in 88s\n",
      "('Start of iteration', 6)\n",
      "('Current loss value:', 7.1418479e+10)\n",
      "Iteration 6 completed in 88s\n",
      "('Start of iteration', 7)\n"
     ]
    }
   ],
   "source": [
    "x = np.random.uniform(0, 255, (1, height, width, 3)) - 128.\n",
    "\n",
    "iterations = 10\n",
    "\n",
    "for i in range(iterations):\n",
    "    print('Start of iteration', i)\n",
    "    start_time = time.time()\n",
    "    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n",
    "                                     fprime=evaluator.grads, maxfun=20)\n",
    "    print('Current loss value:', min_val)\n",
    "    end_time = time.time()\n",
    "    print('Iteration %d completed in %ds' % (i, end_time - start_time))\n",
    "    \n",
    "x = x.reshape((height, width, 3))\n",
    "x = x[:, :, ::-1]\n",
    "x[:, :, 0] += 103.939\n",
    "x[:, :, 1] += 116.779\n",
    "x[:, :, 2] += 123.68\n",
    "x = np.clip(x, 0, 255).astype('uint8')\n",
    "\n",
    "Image.fromarray(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_out_path = 'images/Output/group_picasso.png'\n",
    "Image.fromarray(x).save(image_out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
